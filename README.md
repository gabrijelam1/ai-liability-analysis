# AI Liability Analysis

This project explores legal and ethical liability in artificial intelligence systems, with a focus on case-based reasoning, academic research, and the evolving regulatory landscape in the European Union — particularly the EU AI Act.

## Objectives

- Examine key dimensions of AI-related liability
- Analyze real or hypothetical cases involving automated decision-making
- Reflect on challenges related to accountability, transparency, and human oversight
- Bridge the gap between academic theory and policy frameworks

## Structure

- `report.md` – core analysis covering liability perspectives and ethical questions
- `references.md` – source material, academic works, and legal frameworks

## Key Themes

- Risk distribution in autonomous systems
- Legal personhood and agency in AI
- Preventive governance and transparency obligations
- EU AI Act liability clauses and ethical implications

## Author

**Gabrijela Marić**  
AI & Data Analyst | Streamlit · Chatbots · AI Governance
[LinkedIn](https://www.linkedin.com/in/gabrijelamaric/)